# Evaluating Chunking Strategies for Retrieval 总结

> 原文：`https://research.trychroma.com/evaluating-chunking`  
> GitHub: `https://github.com/brandonstarxel/chunking_evaluation`

在检索增强生成（`RAG`）系统中，如何将长文档高效切分为适合嵌入和检索的小块，是提高系统性能的关键步骤。本文总结了《**`Evaluating Chunking Strategies for Retrieval`**》这篇技术报告的主要内容，重点讨论了文档分块（`chunking`）策略对检索性能的影响，并提出了一种基于 `token` 级别的新型评估方法。

总体来看，本技术报告为文档分块在 `AI` 应用中的角色提供了全新的视角，通过细粒度的评估指标和多种分块策略的比较，展示了如何在实际应用中提高检索系统的效率和准确性。对于从业人员来说，这篇报告不仅有助于理解现有方法的局限性，也为进一步优化和创新分块策略提供了有力支持。

## 1. 引言

### 研究背景与动机

传统的检索评估方法大多聚焦于整个文档的相关性，忽略了实际应用中，仅有部分文本与用户查询相关的事实。现代 `AI` 应用中，`LLM`（大语言模型）在处理输入时，会受到上下文窗口大小和无关信息干扰的影响。为了使 `LLM` 仅处理最相关的部分文本，必须对文档进行合理的分块，从而在检索时只提取真正有用的信息。

### 主要贡献
- **新型评估方法**：作者提出了一种基于 `token` 级别的评估策略，不仅考虑了检索到的相关信息是否完整，还考虑了冗余或无关信息的影响。
- **分块策略比较**：对比分析了多种常用分块方法，并引入了两种新的分块策略，旨在为实际应用提供更高效、更精确的解决方案。

## 2. 评估框架

### 传统方法的局限
传统信息检索评估方法（例如 `nDCG@K`、`MAP@K`）侧重于文档或段落级别的相关性排序，但在 `RAG` 系统中，关键在于提取查询相关的所有 `token`。传统方法忽略了检索过程中可能引入的冗余 `token`，以及相关信息被分散在多个块中的情况。

### 新评估指标
为解决这一问题，报告中引入了以下三个基于 `token` 的指标：

- **精确率（Precision）**：衡量检索结果中真正相关 `token` 所占比例。
- **召回率（Recall）**：衡量相关 `token` 在检索结果中是否被完整覆盖。
- **交并比（IoU）**：借鉴 `Jaccard` 指数，计算检索结果中相关 `token` 与真实相关 `token` 的交并比，用以反映检索结果的紧密程度和冗余情况。

这种评估方式能够更细致地反映出不同分块策略在 `token` 级别上的表现，既关注准确性，也兼顾效率。

## 3. 文档分块策略

### 常用方法
- **固定长度分块**：按固定的字符数或 `token` 数将文档均匀切分，简单直接，但可能忽略语义边界。
- **RecursiveCharacterTextSplitter**：一种递归分块策略，通过分析文本结构（如句子、段落）进行分块，虽能保留部分语义信息，但默认参数下可能无法达到最佳性能。

### 新提出的方法
为进一步提高检索效果，报告中引入了两种新策略：

- **ClusterSemanticChunker**：利用嵌入模型，根据文本语义相似性对文档进行聚类，并生成大小适宜的分块。这种方法能够更好地保持语义连贯性，减少信息断裂。
- **LLMChunker**：直接通过大语言模型的提示，指导模型对文档进行分块，使生成的块更符合实际查询的需要。这种方法在面对复杂语境时表现出较高的灵活性。

## 4. 数据集构建与实验设计

### 数据来源
为验证各分块策略的有效性，作者构建了一个涵盖多领域的评估数据集，包括：

- 政治演讲（如 `State of the Union Address 2024`）
- 维基百科文本（`Wikitext`）
- 聊天记录（`Chatlogs`）
- 金融报告（`Finance`）
- 生物医学文献（`Pubmed`）

这些数据集既有结构化文本，也包含了较为杂乱的信息，从而全面考察分块策略在不同场景下的适用性。

### 查询生成与预处理
- **查询生成**：利用 `LLM` 自动生成与文档内容相关的查询及其对应的文本片段，确保每个查询都有明确的相关信息。
- **去重与过滤**：通过计算嵌入向量的余弦相似度，对生成的查询和对应片段进行去重和相关性过滤，确保数据集的高质量和唯一性。

### 实验设置
在实验中，作者使用不同的分块策略，对各数据集进行检索，并通过**精确率**、**召回率**和 `IoU` 指标评估各策略的性能。实验重点考察：

- 不同策略对 `token` 级别检索效果的影响
- 不同领域文本对策略表现的影响
- 默认参数设置与优化参数下各策略的性能差异

## 5. 实验结果与分析

### 主要发现
- **策略差异显著**：不同分块方法在 `token` 召回率等指标上存在最高约 9% 的差距，说明分块策略选择对检索性能有重要影响。
- **默认参数问题**：一些常见的分块策略在默认参数下表现不佳，表明需要针对具体应用进行参数调优。
- **新策略的优势**：`ClusterSemanticChunker` 和 `LLMChunker` 在部分任务上表现更优，尤其在需要深度语义理解的场景中，可以更好地提取查询相关信息。

### 不同领域的适应性

实验表明，各领域数据对分块策略的敏感度不同。结构化较好的文本（例如政治演讲和维基百科）更容易获得高召回率，而对于结构混乱的文本（如聊天记录），新策略能更好地适应信息碎片化的特点。

## 6. 研究结论与未来展望

### 结论
- 分块策略在 `RAG` 系统中起到关键作用，对系统的准确性和效率都有显著影响。
- 基于 `token` 级别的评估方法能够更真实地反映实际应用中检索系统的性能，而不仅仅是文档整体的相关性。
- 通过对比分析，研究表明不仅要关注传统的分块方法，还需要引入更多语义敏感的策略（如 `ClusterSemanticChunker` 和 `LLMChunker`）。

### 未来工作
- **动态自适应分块**：探索根据文本内容动态调整分块大小和重叠策略的方法，以进一步提升检索效率。
- **扩展评估维度**：结合更多真实应用场景和用户反馈，对评估方法进行多维度扩展。
- **开源工具支持**：报告附带完整代码，鼓励社区基于该框架开展更多领域的实验和改进，推动检索技术在 `AI` 应用中的广泛应用。