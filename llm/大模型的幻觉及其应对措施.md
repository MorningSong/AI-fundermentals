# 大模型的幻觉及其应对措施

## 一、引言

大型语言模型（`LLMs`）能够生成流畅的文本、完成复杂的问答任务，甚至辅助科研与创意工作。然而，这些模型在实际应用中面临一个关键挑战——“**幻觉**”（**Hallucination**），即生成看似合理但偏离事实或用户意图的内容。

例如，模型可能宣称“**埃菲尔铁塔导致巴黎虎灭绝**”，或无视用户指令转而回答无关问题。这类错误轻则误导用户，重则在医疗、法律等高风险场景引发严重后果。**如何应对幻觉**，已成为推动`LLMs`实用化的关键课题。

## 二、大模型的幻觉现象

### 幻觉的定义

**幻觉**指模型生成内容与事实不符或违背用户意图的现象。其本质是模型在缺乏真实知识或逻辑推理能力时，通过“**脑补**”填补信息缺口。

### 幻觉的分类与典型案例

| **类型** | **表现** | **案例** |
|------------------|------------------|---------------------------|
| **事实性幻觉**       | 生成内容违背客观事实 | • 错误归属：“爱迪生发明电话”（实为贝尔）<br>• 虚构实体：“巴黎虎因埃菲尔铁塔灭绝”（无此物种） |
| **忠实性幻觉**       | 生成内容偏离用户指令或上下文 | • 指令忽略：要求翻译却直接回答问题<br>• 逻辑矛盾：解题步骤正确但答案错误 |
| **社会偏见幻觉**     | 输出隐含性别、种族等偏见 | • “护士多为女性”（忽略性别中立描述）<br>• 将“Kim博士”默认关联为韩国人 |

### 幻觉的危害

- **信息误导**：在医疗咨询中，错误症状描述可能导致误诊。
- **信任危机**：用户发现错误后降低对模型的依赖。
- **法律风险**：法律建议中的虚构条款可能引发纠纷。

## 三、幻觉的根源剖析

### 数据缺陷：垃圾进，垃圾出

- **错误信息污染**：训练数据包含过时知识（如“冥王星是行星”）或网络谣言。
- **长尾知识缺失**：专业领域（如罕见病诊疗）或新兴事件（如2024年总统选举）信息不足。
- **偏见放大**：社会媒体数据中的性别、地域偏见被模型继承。

### 训练机制局限

- **自回归范式**：模型仅依赖上文预测下一个词，缺乏全局事实校验。
- **对齐悖论**：强化学习（`RLHF`）可能让模型为讨好人类偏好而牺牲真实性。

### 推理能力不足

- **注意力稀释**：长文本生成时，关键信息被淹没（如“中间诅咒”现象）。
- **过度自信**：模型对错误答案的置信度可能高达90%，缺乏不确定性表达。

## 四、系统化应对策略

### 数据治理：构建高质量知识基座

- **动态数据清洗**：利用事实核查工具（如FACTSCORE）过滤虚假信息。
- **知识图谱融合**：将维基百科等结构化知识嵌入训练，增强事实关联能力。

### **模型优化**：从架构到训练的革命

- **检索增强生成（RAG）**：实时检索外部知识库（如PubMed），避免“闭门造车”。
- **推理链监督**：通过Chain-of-Thought提示强制模型展示推理步骤，暴露逻辑漏洞。

### 解码控制：生成过程的风险拦截

- **对比解码（Contrastive Decoding）**：对比“有上下文”与“无上下文”生成概率，抑制无关内容。
- **自检机制**：生成后触发验证问答（如“你的依据是什么？”），实现内容自洽。

## 五、（普通）用户侧防御

### （一）Prompt 工程

#### **精准指令设计**

- **明确具体**：指令应包含明确的主题、范围和格式要求，避免模糊性。
  - 例如，要求模型“**基于2023年《Nature》期刊最新研究，用中学生能理解的语言，撰写一篇500字以内的量子计算原理介绍，需包含‘量子叠加’和‘量子纠缠’的比喻说明**”，而非简单地“**写一篇关于量子计算的科普文章**”。
- **约束输出**：通过指定字数、语言风格、包含内容等，限制模型的发挥空间，降低幻觉风险。
  - 例如，“**撰写一篇300字的科技新闻摘要，仅包含研究突破和应用前景，使用正式语言。**”
- **引用权威**：要求模型基于特定权威来源回答。
  - 例如“**根据世界卫生组织2023年报告，阐述全球疫苗接种现状。**”
- 示例：

  ```text
  # 模糊指令（易引发幻觉）

  “写一篇关于人工智能的未来发展趋势。”

  # 优化指令（约束输出）

  “基于2023年《AI Research》期刊最新研究，用通俗易懂的语言，撰写一篇300字以内的关于人工智能未来发展趋势的摘要，需包含至少两个具体的应用领域。”
  ```

#### **分步引导**

- **任务分解**：将复杂任务分解为多个简单步骤，逐步引导模型完成。
  - 例如，对于“**分析意大利面制作过程，请：1）列出意大利面制作的5个核心步骤；2. 详细描述每个步骤的注意事项；3. 最后总结常见失败原因及解决方法**”。
- **逻辑串联**：确保各步骤间逻辑连贯，避免模型随意发挥。
  - 例如，“**在分析市场趋势时，先收集近5年数据，再进行线性回归分析，最后预测下一年度趋势。**”
  
#### **反馈修正**

- **直接指出错误**：当模型输出有误时，明确指出问题所在，并要求修正。
  - 例如，“**你提到‘尼罗河发源于安第斯山脉’，这与权威地理资料冲突，请重新核查并修正。**”
- **引导自检**：通过提问引导模型自我检查输出内容。
  - 例如，“**请回顾你刚才的回答，是否有与常识相悖之处？如有，请修正。**”
- **提供参考**：给出正确信息或参考链接，帮助模型修正。
  - 例如，“**参考国家地理网站关于尼罗河的资料，修正发源地描述。**”
- 示例：

  ```text
  # 模型输出
  “尼罗河发源于安第斯山脉，全长6650公里，是世界上最长的河流。”
      
  # 反馈修正
  “你提到‘尼罗河发源于安第斯山脉’，这与权威地理资料冲突，请重新核查并修正。”
      
  # 修正后输出
  “尼罗河发源于东非高原，全长6650公里，是世界上最长的河流。”
  ```

### （二）交叉验证：多模型协作

- **模型组合选择**：选择具有不同训练数据、架构或参数的模型组合，以增加结果多样性。例如，结合GPT-4、Claude和Gemini等不同模型。
- **结果比较与筛选**：对比多个模型输出，筛选出一致且符合常识的结果。对于不一致内容，进一步核查权威资料。
- **投票机制**：当多个模型答案不同时，采用投票方式确定最可信答案。例如，3个模型中2个支持某一答案，则该答案胜出。
- 示例：
  
  ```text
  # 问题
  “2023年诺贝尔物理学奖得主是谁？”
  
  # 模型A输出
  “2023年诺贝尔物理学奖得主是约翰·杜瓦尔。”
  
  # 模型B输出
  “2023年诺贝尔物理学奖得主是安娜·凯恩。”
  
  # 模型C输出
  “2023年诺贝尔物理学奖得主是安娜·凯恩。”
  
  # 交叉验证结果
  根据模型B和模型C的一致性，以及进一步核查官方公告，确定正确答案是安娜·凯恩。
  ```

### （三）检索增强生成（RAG）

- **知识库选择**：根据任务需求选择合适的外部知识库，如医学领域用PubMed，法律领域用LEXIS。
- **实时检索**：在模型生成内容时，实时检索相关知识库，为模型提供准确信息支持。
- **检索结果融合**：将检索到的信息合理融入模型生成内容中，确保输出基于真实可靠知识。
- 示例：
  
  ```text
  # 问题
  “2023年诺贝尔物理学奖得主的研究领域是什么？”
  
  # 检索增强生成
  模型通过检索2023年诺贝尔奖官方网站，获取得主安娜·凯恩的研究领域为“量子光学”，并将其融入回答中。
  
  # 最终回答
  “2023年诺贝尔物理学奖得主安娜·凯恩的研究领域是量子光学，她的工作主要集中在量子信息处理和量子通信方面。”
  ```

## 六、参考论文

《**A Survey on Hallucination in Large Language Models - Principles, Taxonomy, Challenges, and Open Questions**》

- **URL**：`https://doi.org/10.1145/3703155`
- **摘要**：大语言模型（`LLM`）的出现标志着自然语言处理（`NLP`）的重大突破，从而助长了信息获取的范式转移。然而，`LLMS`容易产生幻觉，产生了**合理但非事实的内容**。这种现象对`LLM`在现实世界**信息检索**（`IR`）系统中的可靠性引起了重大关注，并吸引了深入研究以检测和减轻此类幻觉。鉴于`LLM`固有的开放式通用属性，`LLM`幻觉带来了与先前特定于特定任务的模型不同的明显挑战。这种分歧强调了对`LLM`幻觉最近进步的细微理解和全面概述的紧迫性。在这项调查中，我们从`LLM`时代的创新分类学开始，然后深入研究导致幻觉的因素。随后，我们详细介绍了幻觉检测方法和基准。然后，我们的讨论转移给了减轻`LLM`幻觉的代表性方法。此外，我们深入研究了通过检索功能的`LLM`在打击幻觉方面面临的当前限制，为开发更强大的`IR`系统提供了见解。最后，我们强调了有关`LLM`幻觉的有前途的研究方向，包括大型视觉模型中的幻觉以及对`LLM`幻觉中知识边界的理解。
